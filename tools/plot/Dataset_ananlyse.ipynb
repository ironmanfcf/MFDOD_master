{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_coco_data(json_file):\n",
    "    \"\"\"从 JSON 文件中加载 COCO 数据。\"\"\"\n",
    "    with open(json_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def analyze_image_resolutions(data, scatter_size_factor=5, font_size=16, tick_size=14, color='blue', save_path=None, dpi=300):\n",
    "    \"\"\"分析图像分辨率并进行可视化。\n",
    "\n",
    "    参数：\n",
    "    - scatter_size_factor (int): 控制散点大小的因子。\n",
    "    - font_size (int): 标题和标签的字体大小。\n",
    "    - tick_size (int): 刻度标签的字体大小。\n",
    "    - color (str): 散点的颜色。\n",
    "    - save_path (str): 用于保存图形的文件路径。如果为 None，则不保存。\n",
    "    - dpi (int): 保存图像的分辨率，默认是 300 dpi。\n",
    "    \"\"\"\n",
    "    image_dimensions = {}\n",
    "    for image in data['images']:\n",
    "        image_dimensions[image['id']] = (image['width'], image['height'])\n",
    "    \n",
    "    resolution_count = {}\n",
    "    for dimensions in image_dimensions.values():\n",
    "        resolution_count[dimensions] = resolution_count.get(dimensions, 0) + 1\n",
    "    \n",
    "    total_images = sum(resolution_count.values())\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 9))\n",
    "    for dimensions, count in resolution_count.items():\n",
    "        ax.scatter(dimensions[0], dimensions[1], s=count*scatter_size_factor, color=color)\n",
    "    \n",
    "    ax.set_xlabel('宽度', fontsize=font_size)\n",
    "    ax.set_ylabel('高度', fontsize=font_size)\n",
    "    ax.set_title('真实图像分辨率分析', fontsize=font_size, fontweight='bold')\n",
    "    plt.figtext(0.99, 0.01, f'总图像数: {total_images}', horizontalalignment='right', fontsize=12, fontweight='bold')\n",
    "\n",
    "    ax.tick_params(axis='both', which='major', labelsize=tick_size)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(0.7)\n",
    "    ax.spines['bottom'].set_linewidth(0.7)\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=dpi)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# 使用示例\n",
    "color_map = {\n",
    "    0: '#e9e99d',  # 类别ID 1 的颜色\n",
    "    1: '#dda03c',  # 类别ID 2 的颜色\n",
    "    2: '#93b9a7',  # 类别ID 3 的颜色\n",
    "    # 可以继续为每个类别指定颜色\n",
    "}\n",
    "\n",
    "def analyze_object_sizes(data, max_samples=1000, scatter_size_factor=4, font_size=16, tick_size=14, color_map=None, save_path=None, dpi=400, x_range=(0, 300), y_range=(0, 200), x_ticks=[0,50,100,150,200,250,300], y_ticks=[0,50,100,150,200]):\n",
    "    \"\"\"\n",
    "    分析对象尺寸并进行可视化。\n",
    "\n",
    "    参数：\n",
    "    - max_samples (int): 分析的最大样本数。\n",
    "    - scatter_size_factor (int): 控制散点大小的因子。\n",
    "    - font_size (int): 标题和标签的字体大小。\n",
    "    - tick_size (int): 刻度标签的字体大小。\n",
    "    - color_map (dict): 映射类别ID到颜色的字典。\n",
    "    - save_path (str): 用于保存图形的文件路径。如果为 None，则不保存。\n",
    "    - dpi (int): 保存图像的分辨率，默认是 400 dpi。\n",
    "    - x_range (tuple): 横轴范围，格式为 (xmin, xmax)。\n",
    "    - y_range (tuple): 纵轴范围，格式为 (ymin, ymax)。\n",
    "    - x_ticks (list): 横轴刻度。\n",
    "    - y_ticks (list) : 纵轴刻度。\n",
    "    \"\"\"\n",
    "    \n",
    "    object_dimensions = {}\n",
    "    sample_count = 0\n",
    "\n",
    "    category_names = {cat['id']: cat['name'] for cat in data['categories']}\n",
    "\n",
    "    # 如果没有提供颜色映射，则使用默认灰度\n",
    "    if color_map is None:\n",
    "        color_map = {cat_id: 'grey' for cat_id in category_names.keys()}\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    # 可视化每个对象\n",
    "    for annotation in data['annotations']:\n",
    "        if sample_count >= max_samples:\n",
    "            break\n",
    "        bbox = annotation['bbox']\n",
    "        dimensions = (bbox[2], bbox[3])\n",
    "        category_id = annotation['category_id']\n",
    "\n",
    "        color = color_map.get(category_id, 'grey')\n",
    "\n",
    "        ax.scatter(dimensions[0], dimensions[1], s=scatter_size_factor * 10, color=color, \n",
    "                   label=category_names[category_id] if category_names[category_id] not in ax.get_legend_handles_labels()[1] else \"\")\n",
    "\n",
    "        sample_count += 1\n",
    "\n",
    "    # 设置横纵坐标轴范围\n",
    "    ax.set_xlim(*x_range)\n",
    "    ax.set_ylim(*y_range)\n",
    "    \n",
    "    # 设置横纵坐标轴刻度\n",
    "    if x_ticks is not None:\n",
    "        ax.set_xticks(x_ticks)\n",
    "    if y_ticks is not None:\n",
    "        ax.set_yticks(y_ticks)\n",
    "\n",
    "    ax.set_xlabel('Width', fontsize=font_size)\n",
    "    ax.set_ylabel('Height', fontsize=font_size)\n",
    "    ax.set_title('Size distribution of sampled objects in annotations', fontsize=font_size, fontweight='bold')\n",
    "\n",
    "    ax.tick_params(axis='both', which='major', labelsize=tick_size)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(0.7)\n",
    "    ax.spines['bottom'].set_linewidth(0.7)\n",
    "\n",
    "    # 添加图例\n",
    "    ax.legend(loc='upper right', fontsize=12)\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=dpi)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def analyze_category_distribution(data, font_size=16, tick_size=12, cmap='tab20', save_path=None, dpi=300):\n",
    "    \"\"\"分析类别分布并进行可视化。\n",
    "\n",
    "    参数：\n",
    "    - font_size (int): 标题和标签文本的字体大小。\n",
    "    - tick_size (int): 刻度标签的字体大小（尽管饼图通常不使用此设置）。\n",
    "    - cmap (str): 饼图的 Matplotlib 色图。\n",
    "    - save_path (str): 用于保存图形的文件路径。如果为 None，则不保存。\n",
    "    - dpi (int): 保存图像的分辨率，默认是 300 dpi。\n",
    "    \"\"\"\n",
    "    category_counts = {}\n",
    "    for annotation in data['annotations']:\n",
    "        category_id = annotation['category_id']\n",
    "        category_counts[category_id] = category_counts.get(category_id, 0) + 1\n",
    "\n",
    "    category_names = {cat['id']: cat['name'] for cat in data['categories']}\n",
    "    \n",
    "    labels = [category_names[id] for id in category_counts.keys()]\n",
    "    sizes = [category_counts[id] for id in category_counts.keys()]\n",
    "    total = sum(sizes)\n",
    "\n",
    "  \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 12))\n",
    "    wedges, texts, autotexts = ax.pie(sizes, labels=labels, autopct=lambda p: f'{p:.1f}%\\n({int(p*total/100)})',\n",
    "                                      startangle=90, pctdistance=0.85, textprops={'fontsize': font_size}, colors=plt.get_cmap(cmap).colors)\n",
    "\n",
    "    centre_circle = plt.Circle((0, 0), 0.70, fc='white')\n",
    "    fig.gca().add_artist(centre_circle)\n",
    "\n",
    "    ax.axis('equal')\n",
    "    plt.title('class districbution', fontsize=font_size, fontweight='bold')\n",
    "    \n",
    "    ax.tick_params(axis='both', which='major', labelsize=tick_size)\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=dpi)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "data = load_coco_data('/opt/data/private/fcf/mmdetection/data/HazyDet-365k/Real_Haze/train/train_coco.json')\n",
    "# data = load_coco_data('/opt/data/private/fcf/mmdetection/data/HazyDet-365k/train/train_coco.json')\n",
    "\n",
    "# 进行分析\n",
    "# analyze_image_resolutions(data)\n",
    "\n",
    "\n",
    "analyze_object_sizes(data, scatter_size_factor=0.3, color_map = { 0: '#87a4ff',  # 类别ID 1 的颜色\n",
    "    1: '#ff6678',  # 类别ID 2 的颜色\n",
    "    2: '#ffc25e',  # 类别ID 3 的颜色\n",
    "    },max_samples= 2500,save_path='/opt/data/private/fcf/mmdetection/tools/plot/output/Fig5(a).png')  # Analyze only 1000 samples for performance reasons\n",
    "\n",
    "\n",
    "# analyze_category_distribution(data)  # New function to analyze category distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###统计每种种类目标的面积，并用直方图形式来展示\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# 定义一个颜色列表，以供不同类别使用不同的颜色\n",
    "colors = ['b', 'r', 'g', 'c', 'm', 'y', 'k']\n",
    "\n",
    "def plot_histograms_for_categories(json_file_path, num_bins=30, output_dir='output'):\n",
    "    # 确保输出目录存在\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # 读取json文件\n",
    "    with open(json_file_path, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "    \n",
    "    # 创建一个字典来记录每个种类的尺寸信息\n",
    "    category_sizes = defaultdict(list)\n",
    "    \n",
    "    # 获取种类信息\n",
    "    categories = {category['id']: category['name'] for category in coco_data.get('categories', [])}\n",
    "    \n",
    "    # 收集所有面积的集合\n",
    "    all_areas = []\n",
    "    \n",
    "    # 遍历标注信息并记录每个目标的面积\n",
    "    for annotation in coco_data.get('annotations', []):\n",
    "        category_id = annotation['category_id']\n",
    "        category_name = categories.get(category_id, 'Unknown')\n",
    "        bbox = annotation['bbox']\n",
    "        area = bbox[2] * bbox[3]  # 宽 * 高\n",
    "        category_sizes[category_name].append(area)\n",
    "        all_areas.append(area)\n",
    "    \n",
    "    # 对所有面积进行对数变换，避免log(0)的情况，我们过滤面积为0的目标\n",
    "    all_areas = np.array([area for area in all_areas if area > 0])\n",
    "    log_all_areas = np.log(all_areas)\n",
    "    \n",
    "    # 获取对数变换后所有面积的最小值和最大值\n",
    "    min_log_area = min(log_all_areas)\n",
    "    max_log_area = max(log_all_areas)\n",
    "    \n",
    "    # 为每个种类绘制对数直方图\n",
    "    for idx, (category, sizes) in enumerate(category_sizes.items()):\n",
    "        log_sizes = np.log([size for size in sizes if size > 0])\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.hist(log_sizes, bins=num_bins, range=(min_log_area, max_log_area), edgecolor='black', color=colors[idx % len(colors)])\n",
    "        plt.title(f'Distribution of {category} sizes (Log scale)')\n",
    "        plt.xlabel('Log(Area)')\n",
    "        plt.ylabel('Count')\n",
    "        plt.grid(True)\n",
    "        output_path = os.path.join(output_dir, f'{category}_size_distribution.png')\n",
    "        plt.savefig(output_path)\n",
    "        plt.show()\n",
    "\n",
    "# 示例文件路径\n",
    "json_file_path = '/opt/data/private/fcf/mmdetection/data/HazyDet-365k/test/test_coco.json'\n",
    "\n",
    "# 调用函数并生成直方图\n",
    "plot_histograms_for_categories(json_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##统计每种目标的数目\n",
    "\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def count_categories_in_coco(json_file_path):\n",
    "    # 读取json文件\n",
    "    with open(json_file_path, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "    \n",
    "    # 创建一个字典来记录每个种类的目标数量\n",
    "    category_count = defaultdict(int)\n",
    "    \n",
    "    # 获取种类信息\n",
    "    categories = {category['id']: category['name'] for category in coco_data.get('categories', [])}\n",
    "    \n",
    "    # 遍历标注信息并统计各类别的数量\n",
    "    for annotation in coco_data.get('annotations', []):\n",
    "        category_id = annotation['category_id']\n",
    "        category_name = categories.get(category_id, 'Unknown')\n",
    "        category_count[category_name] += 1\n",
    "    \n",
    "    return category_count\n",
    "\n",
    "# 示例文件路径\n",
    "json_file_path = '/opt/data/private/fcf/mmdetection/data/HazyDet-365k/Real_Haze/train/train_coco.json'\n",
    "\n",
    "# 调用函数并打印结果\n",
    "category_count = count_categories_in_coco(json_file_path)\n",
    "for category, count in category_count.items():\n",
    "    print(f\"Category: {category}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: car\n",
      "  Small targets: 8167\n",
      "  Medium targets: 8993\n",
      "  Large targets: 1060\n",
      "\n",
      "Category: bus\n",
      "  Small targets: 69\n",
      "  Medium targets: 363\n",
      "  Large targets: 155\n",
      "\n",
      "Category: truck\n",
      "  Small targets: 112\n",
      "  Medium targets: 290\n",
      "  Large targets: 87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def read_annotations(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        annotations = json.load(f)\n",
    "    return annotations\n",
    "\n",
    "def calculate_area(bbox):\n",
    "    _, _, w, h = bbox\n",
    "    return w * h\n",
    "\n",
    "def categorize_target_size(target_area, image_area):\n",
    "    ratio = (target_area / image_area) * 100  # Convert to percentage\n",
    "    if ratio <= 0.1:\n",
    "        return 'small'\n",
    "    elif ratio <= 1:\n",
    "        return 'medium'\n",
    "    else:\n",
    "        return 'large'\n",
    "\n",
    "def count_targets_by_category_and_size(annotations):\n",
    "    category_size_counts = {}\n",
    "    images_info = {img['id']: img for img in annotations['images']}\n",
    "    \n",
    "    for ann in annotations['annotations']:\n",
    "        image_id = ann['image_id']\n",
    "        image_info = images_info[image_id]\n",
    "        \n",
    "        image_area = image_info['width'] * image_info['height']\n",
    "        target_area = calculate_area(ann['bbox'])\n",
    "        size_category = categorize_target_size(target_area, image_area)\n",
    "        \n",
    "        category_id = ann['category_id']\n",
    "        if category_id not in category_size_counts:\n",
    "            category_size_counts[category_id] = {'small': 0, 'medium': 0, 'large': 0}\n",
    "        \n",
    "        category_size_counts[category_id][size_category] += 1\n",
    "    \n",
    "    return category_size_counts\n",
    "\n",
    "def get_category_names(annotations):\n",
    "    category_names = {cat['id']: cat['name'] for cat in annotations['categories']}\n",
    "    return category_names\n",
    "\n",
    "def main(annotation_file):\n",
    "    annotations = read_annotations(annotation_file)\n",
    "    category_size_counts = count_targets_by_category_and_size(annotations)\n",
    "    category_names = get_category_names(annotations)\n",
    "\n",
    "    for category_id, size_counts in category_size_counts.items():\n",
    "        category_name = category_names.get(category_id, 'Unknown')\n",
    "        print(f\"Category: {category_name}\")\n",
    "        for size, count in size_counts.items():\n",
    "            print(f\"  {size.capitalize()} targets: {count}\")\n",
    "        print()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    annotation_file = \"/opt/data/private/fcf/mmdetection/data/HazyDet-365k/Real_Haze/train/train_coco.json\"\n",
    "    main(annotation_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: car\n",
      "  Small targets: 69971\n",
      "  Medium targets: 147799\n",
      "  Large targets: 24425\n",
      "\n",
      "Category: truck\n",
      "  Small targets: 3229\n",
      "  Medium targets: 5884\n",
      "  Large targets: 2513\n",
      "\n",
      "Category: bus\n",
      "  Small targets: 1568\n",
      "  Medium targets: 3587\n",
      "  Large targets: 5575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "###########COCO标准\n",
    "\n",
    "\n",
    "def read_annotations(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        annotations = json.load(f)\n",
    "    return annotations\n",
    "\n",
    "def calculate_area(bbox):\n",
    "    _, _, w, h = bbox\n",
    "    return w * h\n",
    "\n",
    "def categorize_target_size(target_area):\n",
    "    if target_area < 32 * 32:\n",
    "        return 'small'\n",
    "    elif target_area > 96 * 96:\n",
    "        return 'large'\n",
    "    else:\n",
    "        return 'medium'\n",
    "\n",
    "def count_targets_by_category_and_size(annotations):\n",
    "    category_size_counts = {}\n",
    "    \n",
    "    for ann in annotations['annotations']:\n",
    "        target_area = calculate_area(ann['bbox'])\n",
    "        size_category = categorize_target_size(target_area)\n",
    "        \n",
    "        category_id = ann['category_id']\n",
    "        if category_id not in category_size_counts:\n",
    "            category_size_counts[category_id] = {'small': 0, 'medium': 0, 'large': 0}\n",
    "        \n",
    "        category_size_counts[category_id][size_category] += 1\n",
    "    \n",
    "    return category_size_counts\n",
    "\n",
    "def get_category_names(annotations):\n",
    "    category_names = {cat['id']: cat['name'] for cat in annotations['categories']}\n",
    "    return category_names\n",
    "\n",
    "def main(annotation_file):\n",
    "    annotations = read_annotations(annotation_file)\n",
    "    category_size_counts = count_targets_by_category_and_size(annotations)\n",
    "    category_names = get_category_names(annotations)\n",
    "\n",
    "    for category_id, size_counts in category_size_counts.items():\n",
    "        category_name = category_names.get(category_id, 'Unknown')\n",
    "        print(f\"Category: {category_name}\")\n",
    "        for size, count in size_counts.items():\n",
    "            print(f\"  {size.capitalize()} targets: {count}\")\n",
    "        print()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    annotation_file = \"/opt/data/private/fcf/mmdetection/data/HazyDet-365k/train/train_coco.json\"\n",
    "    main(annotation_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hazydet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
